{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSxEcsf2B6LsvV7JpSRfRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhanshu-2411/Neural-Machine-Translation/blob/tensorflow/Neural_Machine_Translation_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTING REQUIRED LIBRARIES"
      ],
      "metadata": {
        "id": "xic9I95g5AuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W8NCunGZ3SPy"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGdgQSL94y3S",
        "outputId": "cbe45351-c12e-4742-82c5-f7ff158966f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "metadata": {
        "id": "gkI4fPh44y0a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split a loaded document into sentences\n",
        "def to_pairs(doc):\n",
        "\tlines = doc.strip().split('\\n')\n",
        "\tpairs = [line.split('\\t') for line in  lines]\n",
        "\treturn pairs"
      ],
      "metadata": {
        "id": "1vsTJt76410q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean a list of lines\n",
        "def clean_pairs(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor pair in lines:\n",
        "\t\tclean_pair = list()\n",
        "\t\tfor line in pair:\n",
        "\t\t\t# normalize unicode characters\n",
        "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t\tline = line.decode('UTF-8')\n",
        "\t\t\t# tokenize on white space\n",
        "\t\t\tline = line.split()\n",
        "\t\t\t# convert to lowercase\n",
        "\t\t\tline = [word.lower() for word in line]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tline = [word.translate(table) for word in line]\n",
        "\t\t\t# remove non-printable chars form each token\n",
        "\t\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tclean_pair.append(' '.join(line))\n",
        "\t\tcleaned.append(clean_pair)\n",
        "\treturn array(cleaned)"
      ],
      "metadata": {
        "id": "vZtpn3GA44sK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        " dump(sentences, open(filename, 'wb'))\n",
        " print('Saved: %s' % filename)"
      ],
      "metadata": {
        "id": "2Xd0_g9Q7tBp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "folder_path = \"/gdrive/My Drive/Project Data/Blog_Projects/Machine Learning Mastery/\"\n",
        "filename = os.path.join(folder_path, 'deu.txt')\n",
        "doc = load_doc(filename)\n",
        "# split into english-german pairs\n",
        "pairs = to_pairs(doc)\n",
        "# clean sentences\n",
        "clean_pairs = clean_pairs(pairs)\n",
        "# save clean pairs to file\n",
        "save_clean_data(clean_pairs, 'ende.pkl')\n",
        "# spot check\n",
        "for i in range(100):\n",
        " print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "LfwCI4tV5QTQ",
        "outputId": "89035ab9-b3fc-42d4-ae3e-38b2c769e2ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1ed1cdb86f74>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclean_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# save clean pairs to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msave_clean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ende.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# spot check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-da4442a37774>\u001b[0m in \u001b[0;36msave_clean_data\u001b[0;34m(sentences, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save a list of clean sentences to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_clean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m  \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: 'ende.pkl'"
          ]
        }
      ]
    }
  ]
}